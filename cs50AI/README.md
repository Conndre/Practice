# ğŸ¤– CS50 AI 2024 - Lessons
 **CS50's Introduction to Artificial Intelligence with Python**, by Harvard University

---

### 1. ğŸ” Search
- Algoritmos: BFS, DFS, A*
- HeurÃ­stics y A* Search. Minimax. Alpha-Beta Pruning.

ğŸ”— Project: [Degrees (busqueda de actores)](./projects/1_degrees)  
ğŸ”— Project: [Tic Tac Toe](./projects/0_tictactoe)  

---

### 1. ğŸ§  Knowledge
- Propositional Logic. Entailment. Inference. 
- Model Checking. Resolution. First Order Logic.

ğŸ”— Project: [Knights (resolver acertijos lÃ³gicos)](./projects/2_knights)  

---

### 2. ğŸ² Uncertainty
- Probability. Conditional Probability. Random Variables. 
- Independence. Bayesâ€™ Rule. Joint Probability. Bayesian Networks.
- Sampling. Markov Models. Hidden Markov Models.

ğŸ”— Project: [Minesweeper](./projects/3_minesweeper)  

---

### 3. âš™ï¸ Optimization
- Local Search. Hill Climbing. Simulated Annealing. Linear Programming. 
- Constraint Satisfaction. Backtracking Search.

ğŸ”— Project: [Crossword Generator](./projects/4_crossword)  

---

### 4. ğŸ“Š Learning
- Supervised Learning. Nearest-Neighbor 
- Classification. Perceptron Learning. Support Vector Machines. 
- Regression. Loss Functions. Overfitting. Regularization. 
- Reinforcement Learning. Markov Decision Processes. Q-Learning. 
- Unsupervised Learning. k-means Clustering.
- Metrics

ğŸ”— Project: [Shopping](./projects/5_shopping)  

---

### 5. ğŸ§¬ Neural Networks
- Artificial Neural Networks. Activation Functions. Gradient Descent. 
- Backpropagation. Overfitting. 
- TensorFlow. Image Convolution. 
- Convolutional Neural Networks. Recurrent Neural Networks.

ğŸ”— Project: [Traffic (clasificaciÃ³n de imÃ¡genes)](./projects/6_traffic)  

---

### 6. ğŸ—£ï¸ Language
- NLP, tokenization, n-gramas
- Embeddings y Transformers

ğŸ”— Project: [Parser (anÃ¡lisis gramatical)](./projects/7_parser)  


# ğŸ§  NLP - Repaso del Curso

## ğŸ“¦ Enfoque Tradicional
- TokenizaciÃ³n
- N-gramas
- Bag of Words (BoW)
- One-hot Encoding
- TF-IDF
- Modelos clÃ¡sicos (Naive Bayes, SVM...)

## âš¡ Enfoque con Attention
- TokenizaciÃ³n avanzada (BPE, WordPiece)
- Word Embeddings contextuales
- Positional Encoding
- Mecanismo de Self-Attention
- Capas Transformer
- Transfer Learning y fine-tuning

## ğŸ“Œ Comparativa de enfoques
| TÃ©cnica        | Tradicional      | Attention-Based        |
|----------------|------------------|-------------------------|
| TokenizaciÃ³n   | BÃ¡sica           | Avanzada con subpalabras |
| RepresentaciÃ³n | BoW / One-hot    | Embeddings contextuales |
| Contexto       | Limitado         | Global con atenciÃ³n     |
| Modelos        | NB, SVM, etc.    | BERT, GPT, T5â€¦          |


---

## ğŸ“Œ Recursos Extra

- ğŸ”— [Curso oficial en edX](https://cs50.harvard.edu/ai/)
- ğŸ“– *Artificial Intelligence: A Modern Approach* - Russell & Norvig
- 
